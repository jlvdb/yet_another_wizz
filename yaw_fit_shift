#!/usr/bin/env python3
import argparse
import os
import pickle

import numpy as np
from matplotlib.backends.backend_pdf import PdfPages
from yaw_tools.folders import (DEFAULT_EXT_BOOT, DEFAULT_EXT_COV,
                               DEFAULT_EXT_DATA, CCFolder, Folder, binname,
                               find_cc_scales, init_input_folder,
                               init_output_folder)
from yaw_tools.utils import (guess_bin_order, nancov, pack_model_redshifts,
                             write_fit_stats, write_parameters)

from Nz_Fitting import (CurveFit, PowerLawBias, RedshiftData,
                        RedshiftDataBinned, RedshiftHistogram, ShiftModel,
                        ShiftModelBinned)


parser = argparse.ArgumentParser(
    description='SURPRISE!')
parser.add_argument(
    'wdir', metavar='DATAFOLDER',
    help='an output folder of yet_another_wizz')
parser.add_argument(
    'models', metavar='MODELFOLDER',
    help='a folder containing redshift distribution files with redshift keys '
         '(e.g. 0.101z1.201) matching those in the input data folder')
parser.add_argument(
    '--master-key', required=False,
    help='redshift keys (e.g. 0.101z1.201) that identifies the measurement '
         'on the full data sample (only used, if bias is fitted)')
parser.add_argument(
    '--fit-bias', action='store_true',
    help='additinally try to fit the galaxy bias')
parser.add_argument(
    '--use-cov', action='store_true',
    help='use the covariance matrix instead of the standard errors')
parser.add_argument(
    '-o', '--output',
    help='folder in which the output is stored (optional)')


if __name__ == "__main__":

    args = parser.parse_args()
    indir = init_input_folder(args)
    outdir = init_output_folder(args, indir)
    scales = find_cc_scales(indir)

    # global cc binning
    global_binning = np.loadtxt(indir.path_binning_file())

    # open the model directory
    model_dir = Folder(args.models)
    # find any models by matching contents against the redshift key pattern
    models = {}
    for path in model_dir.find(".*\d\.\d*z\d\.\d.*"):
        zbin = binname(path)
        if zbin in models:
            raise ValueError(
                "found multiple occurences of redshift key '%s'" % zbin)
        models[zbin] = path
    if len(models) == 0:
        raise ValueError("no redshift models found")

    # fit the redshift bias
    for scale, scaledir in indir.iter_scales():
        print("==> processing scale: %s" % scale)

        # check which cross-correlation data files exist
        cc_data = scaledir.list_crosscorr_files(DEFAULT_EXT_DATA)
        if len(cc_data) == 0:
            raise ValueError("no cross-correlation data files found")
        elif args.master_key not in cc_data:
            raise KeyError("master key '%s' data not found" % args.master_key)
        # check which cross-correlation bootstrap files exist
        cc_boot = scaledir.list_crosscorr_files(DEFAULT_EXT_BOOT)
        if len(cc_boot) == 0:
            raise ValueError("no cross-correlation bootstraps found")
        if cc_data.keys() != cc_boot.keys():
            raise KeyError(
                "redshift bins of bootstraps do not match data files")
        # check the covariance matrices
        if args.use_cov:
            cc_cov = scaledir.list_crosscorr_files(DEFAULT_EXT_COV)
            if len(cc_cov) == 0:
                raise ValueError(
                    "no cross-correlation covariance matrices found")
            elif args.master_key not in cc_cov:
                raise KeyError(
                    "master key '%s' covariance matrix not found" %
                    args.master_key)
        else:
            cc_cov = None
        # check the models
        if cc_data.keys() != models.keys():
            raise KeyError(
                "redshift bins of redshift models do not match data files")

        # try using the global bin order
        order_file = scaledir.path_bin_order_file()
        if os.path.exists(order_file):
            bin_order = []
            with open(order_file) as f:
                for line in f.readlines():
                    zbin = line.strip("\n")
                    if len(zbin) > 0:
                        bin_order.append(zbin)
        else:
            bin_order = guess_bin_order(cc_data.keys())

        # load the data files
        master_data = None
        bins_data = []
        master_model_data = None
        bins_models_data = []
        for zbin in bin_order:
            data = RedshiftData(*np.loadtxt(cc_data[zbin]).T)
            data.setRealisations(np.loadtxt(cc_boot[zbin])) 
            model = RedshiftHistogram(*np.loadtxt(models[zbin]).T[:2])
            if cc_cov is not None:
                data.setCovariance(np.loadtxt(cc_cov[zbin]))
            if zbin == args.master_key:
                master_data = data
                master_model_data = model
            else:
                bins_data.append(data)
                bins_models_data.append(model)
        if master_data is None:
            master_data = bins_data.pop()
            master_model_data = bins_models_data.pop()
        joint_data = RedshiftDataBinned(bins_data, master_data)
        # load global covariance
        global_cov_file = scaledir.path_global_cov_file("crosscorr")
        if args.use_cov and os.path.exists(global_cov_file):
            joint_data.setCovariance(
                np.loadtxt(scaledir.path_global_cov_file(global_cov_file)))

        # construct models for each bin
        bins_models = [
            ShiftModel(bins_models_data[i], global_binning)
            for i in range(len(bins_data))]
        master_model = ShiftModel(master_model_data, global_binning)

        # construct the fit model
        if args.fit_bias:
            bias = PowerLawBias()
        else:
            bias = None
        model = ShiftModelBinned([*bins_models, master_model], bias)

        # fit the bias model
        optimizer = CurveFit(joint_data, model)
        fitparams = optimizer.optimize()
        print(fitparams)
        paramdir = outdir[scale].join("shift_parameters")
        print("writing fit parameters to: %s/" % os.path.basename(paramdir))
        write_fit_stats(fitparams, paramdir, precision=3, notation="decimal")
        write_parameters(fitparams, paramdir, precision=4, notation="decimal")

        # compute the output redshift distributions
        model_containers = pack_model_redshifts(
            model, fitparams, [
                m.z for m in [*bins_models_data, master_model_data]])
        joint_models = RedshiftDataBinned(
            model_containers[:-1], model_containers[-1])
        joint_models.setCovariance(
            nancov(joint_models.getRealisations().T))

        # write the shifted redshift histograms
        for zbin, data in zip(bin_order, model_containers):
            outpath = outdir[scale].path_shiftfit_file(".*", zbin)
            print("writing model data to: %s" % os.path.basename(outpath))
            header = "col 1 = mean redshift\n"
            header += "col 2 = shifted n(z) (from %s)\n" % models[zbin]
            header += "col 3 = error"
            np.savetxt(
                outpath.replace(".*", DEFAULT_EXT_DATA),
                np.stack([data.z, data.n, data.dn]).T, header=header)
            np.savetxt(
                outpath.replace(".*", DEFAULT_EXT_BOOT),
                data.getRealisations(),
                header="shifted n(z) realisations (from %s)" % models[zbin])
            np.savetxt(
                outpath.replace(".*", DEFAULT_EXT_COV),
                data.getCovariance(),
                header=(
                    "shifted n(z) (from %s) covariance matrix" % models[zbin]))

        # store global covariance matrix
        outpath = outdir[scale].path_global_cov_file("shiftfit")
        print(
            "writing global covariance matrix to: %s" %
            os.path.basename(outpath))
        header = "global shifted n(z) "
        header += "(from %s) covariance matrix" % os.path.dirname(models[zbin])
        np.savetxt(outpath, joint_models.getCovariance(), header=header)
        # store the order for later use
        outpath = outdir[scale].path_bin_order_file()
        with open(outpath, "w") as f:
            for zbin in bin_order:
                f.write("%s\n" % zbin)

