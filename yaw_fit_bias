#!/usr/bin/env python3
import argparse
import os
# disable threading in numpy
os.environ["OMP_NUM_THREADS"] = "1"
os.environ['OPENBLAS_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'

import numpy as np
from matplotlib import pyplot as plt
from Nz_Fitting import (CurveFit, PowerLawBias, RedshiftData,
                        RedshiftDataBinned)
from yaw_tools.bias_fitting import fit_bias, apply_bias_fit
from yaw_tools.folders import (DEFAULT_EXT_BOOT, DEFAULT_EXT_COV,
                               DEFAULT_EXT_DATA, find_cc_scales,
                               init_input_folder, init_output_folder)
from yaw_tools.utils import (guess_bin_order, write_fit_stats,
                             write_global_cov, write_nz_data,
                             write_parameters)
from yet_another_wizz.utils import load_json


parser = argparse.ArgumentParser(
    description='Estimate the cross-correlation bias by fitting the weighted '
                'sum of redshift bins to the full data sample.')
parser.add_argument(
    'wdir', metavar='DATAFOLDER',
    help='an output folder of yet_another_wizz')
parser.add_argument(
    '--master-key', required=True,
    help='redshift keys (e.g. 0.101z1.201) that identifies the measurement '
         'on the full data sample (only used, if bias is fitted)')
parser.add_argument(
    '--cov-type', default="global", choices=RedshiftData._covmat_types,
    help='way in which the covariance information is used')
parser.add_argument(
    '--no-z-check', action='store_true',
    help='do not check if the redshift sampling points match')
parser.add_argument(
    '-o', '--output', required=True,
    help='folder in which the output is stored')


if __name__ == "__main__":

    args = parser.parse_args()
    indir = init_input_folder(args)
    outdir = init_output_folder(args, indir)
    scales = find_cc_scales(indir)

    # fit the redshift bias
    for scale, scaledir in indir.iter_scales():
        print("==> processing scale: %s" % scale)

        # check which cross-correlation data files exist
        cc_data = scaledir.list_crosscorr_files(DEFAULT_EXT_DATA)
        if len(cc_data) == 0:
            raise ValueError("no cross-correlation data files found")

        # figure out the bin order
        order_file = scaledir.path_bin_order_file()
        if os.path.exists(order_file):
            bin_order = []
            with open(order_file) as f:
                for line in f.readlines():
                    zbin = line.strip("\n")
                    if len(zbin) > 0:
                        bin_order.append(zbin)
        else:
            bin_order = guess_bin_order(cc_data.keys())

        # load the bin weights
        weight_file = scaledir.path_weights_file()
        if not os.path.exists(weight_file):
            raise OSError("bin weights file not found")
        weight_dict = load_json(weight_file)
        # sort and normalize the weights
        weights = np.fromiter(
            (weight_dict[zbin] for zbin in bin_order[:-1]), dtype=np.float32)
        weights /= weight_dict[bin_order[-1]]

        # load the data
        bins_data = []
        for zbin in bin_order:
            data_path = os.path.splitext(cc_data[zbin])[0]
            bins_data.append(RedshiftData.read(data_path))
            # load the header key
            with open(cc_data[zbin]) as f:
                for line in f.readlines():
                    if "col 2 = correlation amplitude" in line:
                        header_line = line.strip("\n")
                        break
        master_data = bins_data.pop()
        # create a joint data container (automatically computes global covar.)
        print("selecting covariance type: %s" % args.cov_type)
        master_data.setCovMatType(args.cov_type)
        joint_data = RedshiftDataBinned(bins_data, master_data)

        # fit the bias model
        bias_model = PowerLawBias()
        fitparams = fit_bias(
            joint_data, weights, bias_model,
            check_binning=not(args.no_z_check),
            max_nfev=bias_model.getParamNo() * 1000)
        print(fitparams)
        paramdir = outdir[scale].join("bias_parameters")
        print("writing fit parameters to: %s/" % os.path.basename(paramdir))
        write_fit_stats(fitparams, paramdir, precision=3, notation="decimal")
        write_parameters(fitparams, paramdir, precision=3, notation="decimal")

        # evaluate the bias model
        bias_data, joint_corrected = apply_bias_fit(
            joint_data, bias_model, fitparams)

        # write the bias model files
        header = "col 1 = mean redshift\n"
        header += "col 2 = bias model\n"
        header += "col 3 = bias error"
        write_nz_data(
            outdir[scale].path_bias_file(""), bias_data,
            hdata=header, hboot="bias realisations",
            hcov="bias covariance matrix", stats=False,
            dtype_message="bias  model")

        # write the corrected redshift distributions
        hkey = "%s / bias model" % header_line.strip(")")
        hkey = hkey.split("(")[-1]
        header = "col 1 = mean redshift\n"
        header += "col 2 = correlation amplitude (%s)\n" % hkey
        header += "col 3 = amplitude error"
        print("writing n(z) statistics to: stats/")
        for zbin, data in zip(bin_order, joint_corrected.iterData()):
            write_nz_data(
                outdir[scale].path_crosscorr_file("", zbin), data,
                hdata=header,
                hboot="correlation amplitude (%s) realisations" % hkey,
                hcov="correlation amplitude (%s) covariance matrix" % hkey,
                stats=True)
        # store global covariance matrix
        header = "global correlation amplitude "
        header += "(%s) covariance matrix" % hkey
        write_global_cov(
            outdir[scale], joint_corrected, bin_order, header, "crosscorr")

        # make check plots
        plot_file = outdir[scale].path_bias_file(".*")
        print("writing fit check plot to: %s" % os.path.basename(plot_file))
        fig = bias_data.plot(lines=True)
        fig.set_xlabel(r"$z$", fontsize=13)
        fig.no_gaps()
        fig.savefig(plot_file.replace(".*", ".pdf"))
        fig.savefig(plot_file.replace(".*", ".png"))
        plt.close(fig.fig)
