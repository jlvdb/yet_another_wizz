#!/usr/bin/env python3
import argparse
import os
import warnings
from collections import Counter
from hashlib import md5

import numpy as np
from yaw_tools.folders import (DEFAULT_EXT_BOOT, DEFAULT_EXT_COV,
                               DEFAULT_EXT_DATA, CCFolder,
                               check_autocorrelation, find_cc_scales,
                               init_input_folder, init_output_folder)
from yaw_tools.pickles import (AutoCorrelationPickle, CrossCorrelationPickle,
                               convert_pickle)
from yaw_tools.utils import nancov


parser = argparse.ArgumentParser(
    description='Unpickles yet_another_wizz region pickle files, optionally '
                'applying bias corrections.')
parser.add_argument(
    'wdir', metavar='DATAFOLDER',
    help='an output folder of yet_another_wizz')
parser.add_argument(
    '--bias-spec',
    help='suffix of the auto-correlation files to apply for correcting the '
         'spectroscopic bias (optional)')
parser.add_argument(
    '--bias-phot',
    help='suffix of the auto-correlation files to apply for correcting the '
         'photometric bias (optional)')
params_group.add_argument(
    '--seed', default='KV450',
    help='string to seed the random generator (default: %(default)s)')
parser.add_argument(
    '--n-boot', type=int, default=1000,
    help='number of bootstrap realisations for covariance estimation')
parser.add_argument(
    '--store-boot', action='store_true',
    help='save the bootstrap realisations in separate files')
parser.add_argument(
    '--store-cov', action='store_true',
    help='save covariance matrices in separate files')
parser.add_argument(
    '--cov-order', nargs='*',
    help='order of redshift keys (e.g. 0.101z1.201) in which the cross-'
         'correlation files are inserted into the global covariance matrix, '
         'if not given no global covariance is computed')
parser.add_argument(
    '-o', '--output',
    help='folder in which the output is stored (optional)')


if __name__ == "__main__":

    args = parser.parse_args()
    indir = init_input_folder(args)
    outidr = init_output_folder(args, indir)
    scales = find_cc_scales(indir)

    output_types = ["redshift distributions"]
    if args.store_boot:
        output_types.append("bootstrap samples")
    if args.store_cov:
        output_types.append("covariance matrices")
        if args.cov_order is not None:
            output_types.append("global covariance")
    print("producing output: %s" % ", ".join(output_types))

    # initialize the random state
    hasher = md5(bytes(args.seed, "utf-8"))
    hashval = bytes(hasher.hexdigest(), "utf-8")
    np.random.seed(np.frombuffer(hashval, dtype=np.uint32))
    # global should be always the same once initialized
    boot_idx = None

    # convert the pickles
    for scale, scaledir in indir.iter_scales():
        print("==> processing scale: %s" % scale)

        # check which correlation pickles exist
        cc_pickles = scaledir.list_crosscorr_files(".pkl")
        if len(cc_pickles) == 0:
            raise ValueError("no cross-correlation pickles found")
        # figure out whether to use spectroscopic auto-correlation
        ac_spec_pickle, use_wss = check_autocorrelation(
            scaledir, args.bias_spec, "spec.")
        # figure out whether to use photometric auto-correlation
        ac_phot_pickle, use_wpp = check_autocorrelation(
            scaledir, args.bias_phot, "phot.")

        # NaNs are to be expected so we ignore warnings
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")

            # process auto-correlation pickles and compute the bias correction
            header_key = "w_sp"
            if use_wss:
                amp_product, amp_product_samples = convert_pickle(
                    outdir[scale], ac_spec_pickle,
                    AutoCorrelationPickle, "w_ss")
                header_key += " / bias_spec"
            if use_wpp:
                amplitudes, samples = convert_pickle(
                    outdir[scale], ac_phot_pickle,
                    AutoCorrelationPickle, "w_pp")
                try:
                    amp_product *= amplitudes
                    amp_product_samples *= samples
                except NameError:
                    amp_product = amplitudes
                    amp_product_samples = samples
                header_key += " / bias_phot"
            # apply the bias correction
            try:
                bias = np.sqrt(amp_product)
                bias_samples = np.sqrt(amp_product_samples)
            except NameError:
                bias, bias_samples = None, None

            # process the cross-correlation pickles
            samples = {}  # needed for correlation between bins
            for zbin, pickle_path in cc_pickles.items():
                amplitudes, samples[zbin] = convert_pickle(
                    outdir[scale], pickle_path,
                    CrossCorrelationPickle, header_key,
                    bias=bias, bias_samples=bias_samples)

            # compute global covariance matrix
            if args.cov_order is not None and args.store_cov:
                data_keys = samples.keys()
                global_samples = None
                for zbin in args.cov_order:
                    try:
                        if global_samples is None:
                            global_samples = samples[zbin]
                        else:
                            global_samples = np.concatenate([
                                global_samples, samples[zbin]])
                    except KeyError:
                        string = "redshift bin '%s' from --cov-order " % zbin
                        string += "not found"
                        raise KeyError(string)
                # store global covariance matrix
                outpath = outdir[scale].incorporate(
                    os.path.basename(pickle_path).split("_")[0] +
                    "_global%s" % DEFAULT_EXT_COV)
                print(
                    "writing global covariance matrix to: %s" %
                    os.path.basename(outpath))
                header = "global correlation amplitude "
                header += "(%s) covariance matrix" % header_key
                np.savetxt(outpath, nancov(global_samples), header=header)
                # store the order for later use
                with open(os.path.splitext(outpath)[0] + ".order", "w") as f:
                    for zbin in args.cov_order:
                        f.write("%s\n" % zbin)
            elif args.cov_order is None and args.store_cov:
                print("omitting global covariance estimation")
