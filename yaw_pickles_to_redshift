#!/usr/bin/env python3
import argparse
import os
import warnings
from collections import Counter
from hashlib import md5

import numpy as np
from yaw_tools.folders import (DEFAULT_EXT_COV, CCFolder,
                               check_autocorrelation, find_cc_scales,
                               init_input_folder, init_output_folder)
from yaw_tools.pickles import (AutoCorrelationPickle, CrossCorrelationPickle,
                               PickleConverter)
from yaw_tools.utils import nancov


parser = argparse.ArgumentParser(
    description='Unpickles yet_another_wizz region pickle files, optionally '
                'applying bias corrections.')
parser.add_argument(
    'wdir', metavar='DATAFOLDER',
    help='an output folder of yet_another_wizz')
parser.add_argument(
    '--bias-spec',
    help='suffix of the auto-correlation files to apply for correcting the '
         'spectroscopic bias (optional)')
parser.add_argument(
    '--bias-phot',
    help='suffix of the auto-correlation files to apply for correcting the '
         'photometric bias (optional)')
parser.add_argument(
    '--seed', default='KV450',
    help='string to seed the random generator (default: %(default)s)')
parser.add_argument(
    '--n-boot', type=int, default=1000,
    help='number of bootstrap realisations for covariance estimation')
parser.add_argument(
    '--cov-order', nargs='*',
    help='order of redshift keys (e.g. 0.101z1.201) in which the cross-'
         'correlation files are inserted into the global covariance matrix, '
         'if not given no global covariance is computed')
parser.add_argument(
    '-o', '--output',
    help='folder in which the output is stored (optional)')


if __name__ == "__main__":

    args = parser.parse_args()
    indir = init_input_folder(args)
    outdir = init_output_folder(args, indir)
    scales = find_cc_scales(indir)

    # initialize the random state
    hasher = md5(bytes(args.seed, "utf-8"))
    hashval = bytes(hasher.hexdigest(), "utf-8")
    np.random.seed(np.frombuffer(hashval, dtype=np.uint32))
    # initialize region bootstrapping of pickle converter, all data output
    # will be based on the same region realizations
    pkl2data = PickleConverter(args.n_boot)

    # convert the pickles
    for scale, scaledir in indir.iter_scales():
        print("==> processing scale: %s" % scale)

        # check which correlation pickles exist
        cc_pickles = scaledir.list_crosscorr_files(".pkl")
        if len(cc_pickles) == 0:
            raise ValueError("no cross-correlation pickles found")
        # figure out whether to use spectroscopic auto-correlation
        ac_spec_pickle, use_wss = check_autocorrelation(
            scaledir, args.bias_spec, "spec.")
        # figure out whether to use photometric auto-correlation
        ac_phot_pickle, use_wpp = check_autocorrelation(
            scaledir, args.bias_phot, "phot.")

        # NaNs are to be expected so we ignore warnings
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")

            # process auto-correlation pickles and compute the bias correction
            header_key = "w_sp"
            if use_wss:
                pkl2data.set_bias(None, None)  # clear bias arrays
                pkl2data.load_pickle(ac_spec_pickle, AutoCorrelationPickle)
                pkl2data.write_output(outdir[scale], "w_ss")
                amp_product = pkl2data.get_amplitudes()
                amp_product_samples = pkl2data.get_samples()
                header_key += " / bias_spec"
            if use_wpp:
                pkl2data.set_bias(None, None)  # clear bias arrays
                pkl2data.load_pickle(ac_phot_pickle, AutoCorrelationPickle)
                pkl2data.write_output(outdir[scale], "w_pp")
                try:
                    amp_product *= pkl2data.get_amplitudes()
                    amp_product_samples *= pkl2data.get_samples()
                except NameError:
                    amp_product = pkl2data.get_amplitudes()
                    amp_product_samples = pkl2data.get_samples()
                header_key += " / bias_phot"
            # apply the bias correction
            try:
                bias = np.sqrt(amp_product)
                bias_samples = np.sqrt(amp_product_samples)
            except NameError:
                bias, bias_samples = None, None

            # process the cross-correlation pickles
            samples = {}  # needed for correlation between bins
            for zbin, pickle_path in cc_pickles.items():
                pkl2data.set_bias(bias, bias_samples)
                pkl2data.load_pickle(pickle_path, CrossCorrelationPickle)
                pkl2data.write_output(outdir[scale], header_key)
                samples[zbin] = pkl2data.get_samples()

            # compute global covariance matrix
            if args.cov_order is None:
                print("omitting global covariance estimation")
            else:
                data_keys = samples.keys()
                global_samples = None
                for zbin in args.cov_order:
                    try:
                        if global_samples is None:
                            global_samples = samples[zbin]
                        else:
                            global_samples = np.concatenate([
                                global_samples, samples[zbin]])
                    except KeyError:
                        string = "redshift bin '%s' from --cov-order " % zbin
                        string += "not found"
                        raise KeyError(string)
                # store global covariance matrix
                outpath = outdir[scale].incorporate(
                    os.path.basename(pickle_path).split("_")[0] +
                    "_global%s" % DEFAULT_EXT_COV)
                print(
                    "writing global covariance matrix to: %s" %
                    os.path.basename(outpath))
                header = "global correlation amplitude "
                header += "(%s) covariance matrix" % header_key
                np.savetxt(outpath, nancov(global_samples), header=header)
                # store the order for later use
                outpath = outdir[scale].path_bin_order_file()
                with open(outpath, "w") as f:
                    for zbin in args.cov_order:
                        f.write("%s\n" % zbin)
